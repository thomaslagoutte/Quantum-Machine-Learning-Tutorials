{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "668ee736",
   "metadata": {},
   "source": [
    "## Tutorial 5: Quantum Neural Network\n",
    "#### Julien Rauch, January 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66498e9",
   "metadata": {},
   "source": [
    "### 1 - Introduction\n",
    "This time, we will use our quantum circuit (feature map) directly as a quantum neural network inserted in an optimization loop:\n",
    "\n",
    "- Each input data vector is embedded into Hilbert space by the feature map of $n$ qubits with a set of parameters $\\theta$ and produces an output quantum state of $n$ qubits. This is then measured to produce an output data vector of $2^n$ values (probabilities), that corresponds to the projection of $\\ket{\\phi_{\\theta}(x)} = U(x, \\theta)\\ket{0}^n$.\n",
    "\n",
    "- The CPU then clusters the data based on projections of the quantum states of each input data point. This clustering is evaluated using an NMI metric based on the known labels for each input data point. Finally, a Cobyla optimizer experiments with new sets of parameters $\\theta$ to obtain new embeddings, then new clusters, and ultimately achieve a better NMI metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdadc669",
   "metadata": {},
   "source": [
    "### 2 - Quantum Circuit Design: Feature Map as QNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa82d4b9",
   "metadata": {},
   "source": [
    "We will create a circuit consisting of the embedding section from the previous tutorial, and we will add a parametric section consisting of $Ry$ gates and $controled~Rz$ gates connected circularly (inspired of EfficientSU2 feature map). \n",
    "\n",
    "Here is the circuit in question for a single layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecbea47",
   "metadata": {},
   "source": [
    "![image](./img/circuit_var.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embbeding_parametric_circuit(nb_qubit, nb_feature, name_param=\"parameters\", name_input=\"input\", nb_layer=1):\n",
    "    \"\"\"\n",
    "        nb_qubit : number of qubits in the circuit\n",
    "        nb_feature : number of features of a data vector\n",
    "        name_param : name will be the identifier of the ParameterVector corresponding to the parameters\n",
    "        name_input : name will be the identifier of the ParameterVector corresponding to the input\n",
    "        nb_layer : number of layers in the circuit\n",
    "        This function returns an embedding and variational circuit: the QNN.\n",
    "    \"\"\"\n",
    "    #TODO create the embedding circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the circuit\n",
    "embbeding_parametric_circuit(4,2).draw() # Basic printing, you can improve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd60e0",
   "metadata": {},
   "source": [
    "### 3 - Global Data Embedding Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e86c94",
   "metadata": {},
   "source": [
    "We need a function that acheving the **data embedding loop**:\n",
    "\n",
    "- Successively load the input data vectors with fixed parameters $\\theta$ defined in the quantum circuit, then store and return the projections of the output quantum states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit_ibm_runtime import SamplerV2 as Sampler\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "import numpy as np\n",
    "\n",
    "nb_shots = 2000 #1024 by default\n",
    "sim = AerSimulator(shots=nb_shots)\n",
    "\n",
    "# create the pass manager (managing and optimizing the quantum circuit)\n",
    "pm = generate_preset_pass_manager(backend=sim, optimization_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data embedding loop function\n",
    "def embedding_data(nb_qubit, nb_feature, dataset, parameters, backend, pass_manager, nb_layer=1):\n",
    "    \"\"\"\n",
    "        nb_qubit : number of qubits in the circuit\n",
    "        nb_feature : number of features of a data vector\n",
    "        dataset : data to embedded\n",
    "        parameters : parameters of the variational circuit\n",
    "        backend : backend to run the circuit\n",
    "        pass_manager : pass manager to transpose the circuit by adapting it to the backend\n",
    "        nb_layer : number of layers in the circuit\n",
    "        This function returns the embedded data\n",
    "    \"\"\"\n",
    "    res = []       # list of output quantum state projection\n",
    "    n=len(dataset) # number of projections\n",
    "\n",
    "    #TODO\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec72cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution of the data embedding loop on a small dataset with random theta parameters\n",
    "embedding_data(1, 1, [[0.2], [0.8], [3.4]], np.random.random(1), sim, pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64860a98",
   "metadata": {},
   "source": [
    "### 4 - Data Clustering using outputs of the Quantum Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb888c5b",
   "metadata": {},
   "source": [
    "In this section, we aim to perform a data clustering using the projections provided by our previous parametric circuit (QNN) with random parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "# Importing the \"moons\" dataset and the associated labels\n",
    "X_moons, y_moons = make_moons(100, noise=0.05)\n",
    "plt.scatter(X_moons[:,0], X_moons[:,1], c=y_moons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e026f9e",
   "metadata": {},
   "source": [
    "Do the clustering like in the previous tutorial (for the parameters uses ```np.random.random``` for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6e39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Do the preprocessing\n",
    "# X_moons = ...\n",
    "\n",
    "\n",
    "# TODO Call your data embedding function and run a spectral clustering (With calculation of the affinity matrix on the fly)\n",
    "# embedded_data = ...\n",
    "\n",
    "\n",
    "# TODO Compute and print the NMI result\n",
    "\n",
    "\n",
    "# TODO Display the dataset with computed labeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89169cb2",
   "metadata": {},
   "source": [
    "## 5 - Complete classification algorithm:\n",
    "### - Use of previous data clustering \n",
    "### - Optimization of embedding performed by QNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a33d2",
   "metadata": {},
   "source": [
    "This section is devoted to the implementation and experimentation of the complete ML algorithm in order to obtain optimal classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1407bd",
   "metadata": {},
   "source": [
    "### 5.1 - Display Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ce727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "score_evolution = []\n",
    "\n",
    "#This function will display the result of our classification and the evolution of the score (NMI) at each loop (epoch).\n",
    "def plot_training_progress(cluster_labels_save):\n",
    "\n",
    "    if len(score_evolution) < 2:\n",
    "        return\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "    # NMI\n",
    "    ax1.set_title(\"Classification Score\")\n",
    "    ax1.plot(score_evolution)\n",
    "    ax1.set_xlabel(\"epoch\")\n",
    "    ax1.set_ylabel(\"NMI\")\n",
    "\n",
    "    # Labeling\n",
    "    ax2.set_title(\"Labeling\")\n",
    "    ax2.scatter(X_moons[:,0], X_moons[:,1], c=cluster_labels_save)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a057405",
   "metadata": {},
   "source": [
    "### 5.2 - Design of the objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922ecea",
   "metadata": {},
   "source": [
    "To optimize the classification we first design an \"objective function\" that takes as parameters those that must be supplied to our circuit ($\\theta$ parameters) and returns a score that we want to minimize, we will use the ```minimize``` function from the ```scipy.optimize``` module. \n",
    "This objective function will be used at the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d7d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_objective(parameter):\n",
    "    # TODO: call your data embedding function, run a spectral clustering providing the cluster labels \n",
    "    # and compute the NMI result (nmi)\n",
    "\n",
    "\n",
    "    # We store the NMI score in the global score list and call the previously defined plot_training_progress function, \n",
    "    # which will display the progress of our training\n",
    "    score_evolution.append(nmi)\n",
    "    plot_training_progress(cluster_labels)\n",
    "\n",
    "    # TODO return the score to minimize \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47582ea2",
   "metadata": {},
   "source": [
    "### 5.3 - Run the learning loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783a41a",
   "metadata": {},
   "source": [
    "Use the ```minimize``` function from the ```scipy.optimize``` module on the previous objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize the score list to store the evolution of the NMI.\n",
    "score_evolution = []\n",
    "\n",
    "#TODO Initialize the parameters\n",
    "# x0 = ...\n",
    "\n",
    "#TODO Run minimize function (method='COBYLA') and stock the result in a variable\n",
    "# res = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4dc6c5",
   "metadata": {},
   "source": [
    "Display the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dbb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: call your data embedding function and run a spectral clustering with the optimized parameters\n",
    "#embedded_data = ...\n",
    "\n",
    "\n",
    "# TODO Compute and print the NMI result\n",
    "\n",
    "\n",
    "# TODO Display the dataset with computed labeling\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
