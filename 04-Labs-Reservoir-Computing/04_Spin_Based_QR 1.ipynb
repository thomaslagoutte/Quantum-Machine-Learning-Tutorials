{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c4035d",
   "metadata": {},
   "source": [
    "## Laboratory 4: Simulation of a Spin-Based Quantum Reservoir Computer for time-series prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd345b2",
   "metadata": {},
   "source": [
    "### 1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc43519",
   "metadata": {},
   "source": [
    "Quantum Reservoir Computing (QRC) is a paradigm that extends reservoir computing to quantum systems. A fixed (non-variational) quantum dynamical system acts as a reservoir that processes time-dependent inputs through its temporal evolution, while learning is restricted to a classical readout layer. This approach avoids training the internal quantum dynamics and makes QRC particularly suitable for near-term quantum devices (NISQ).\n",
    "\n",
    "In spin-based QRC, the reservoir consists of interacting spins evolving under a fixed Hamiltonian. Classical inputs are injected sequentially by encoding them into the quantum state of boundary spins, which interact with the reservoir. This procedure induces an effective open-system dynamics that provides both nonlinearity and memory, key properties for time-series processing.\n",
    "\n",
    "In this laboratory, you will simulate a spin-based quantum reservoir computer for time-series prediction. You will implement amplitude encoding of inputs, simulate the density-matrix evolution of the reservoir, and extract classical features from quantum measurements. A linear readout will then be trained to predict future values of a temporal signal (a chaotic time series from the Lorenz System).\n",
    "\n",
    "The objective of this lab is to understand how quantum dynamics, input encoding, and measurement combine to produce computational capabilities, and to gain hands-on experience with the simulation and evaluation of a quantum reservoir computing systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c54d734",
   "metadata": {},
   "source": [
    "### 2 - Spin-based Quantum Reservoir Computing Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c06cae2",
   "metadata": {},
   "source": [
    "To simulate the quantum reservoir computer, We will uses an Hamiltonian describing interactions between spins (similar to that present in class) and following the mathematical form highlighted in the following reference : ***Quantum reservoir computing: a reservoir approach toward quantum machine learning on near-term quantum devices***: https://arxiv.org/abs/2011.04890\n",
    "\n",
    "The mathemetical form of the hamiltonian reads :\n",
    "\n",
    "$$H = \\sum_{i,j} J_{i,j} X_i X_j + h \\sum_i Z_i$$\n",
    "\n",
    "with $X_i = I \\otimes I ... \\otimes I \\otimes X \\otimes I ... \\otimes I$, $X$ the Pauli-X operator, and $I$ the identity operator acting on a single qubit.\n",
    "\n",
    "For example, Consideriong a QRC with two nodes, we would have :\n",
    "- $X_0 = X \\otimes I$\n",
    "- $X_1 = I \\otimes X$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad4e54",
   "metadata": {},
   "source": [
    " ## Work to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c8134",
   "metadata": {},
   "source": [
    "### 3-Implementation Of Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755b264",
   "metadata": {},
   "source": [
    "***Question 1*** :   Create in Numpy the matrices for the $X$, $Y$, $Z$  Pauli operators and $I$ the identity operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb53dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ea5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Create the matrices for the X, Y, Z  Pauly gates and I the identity in Numpy.\n",
    "# X = \n",
    "# Y =\n",
    "# Z =\n",
    "# I ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10496f72",
   "metadata": {},
   "source": [
    "***Question 2*** :  Create in Numpy the matrices for operators $X_i$, $Z_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO return the numpy version of Xi\n",
    "def Xi(nb_node, i):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d474067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO return the numpy version of Zi\n",
    "def Zi(nb_node, i):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f899d6c",
   "metadata": {},
   "source": [
    "***Question 3*** :   Create in Numpy the matrix for the Hamiltonian operator using the expression shown in Section 2. The interaction being bidirectional, the adjacency of matrix of the network containing coefficient $J_{i,j}$ is squared and symmetric (Note : the transverse field coefficients $h$ are on the diagonal on matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c865216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO return the numpy Hamiltonian for the given weigth\n",
    "def make_Hamiltonian(nb_node, weight):\n",
    "    res = np.zeros((2**nb_node, 2**nb_node))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770befbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_Hamiltonian(2, np.array([[1.0,0.2], [-0.7,1.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62917772",
   "metadata": {},
   "source": [
    "### 4- Data input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d80376",
   "metadata": {},
   "source": [
    "The following code allows to easily compute the partial trace for an operator. This will be a useful function for the computation of the temporal evolution of the density operator describiung aggregated state of the reservoir and boundary input qubits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d11c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cvxpy/cvxpy/issues/563#issuecomment-414081249\n",
    "\n",
    "def partial_trace(rho, dims, axis=0):\n",
    "    \"\"\"\n",
    "    Takes partial trace over the subsystem defined by 'axis'\n",
    "    rho: a matrix\n",
    "    dims: a list containing the dimension of each subsystem\n",
    "    axis: the index of the subsytem to be traced out\n",
    "    (We assume that each subsystem is square)\n",
    "    \"\"\"\n",
    "    dims_ = np.array(dims)\n",
    "    # Reshape the matrix into a tensor with the following shape:\n",
    "    # [dim_0, dim_1, ..., dim_n, dim_0, dim_1, ..., dim_n]\n",
    "    # Each subsystem gets one index for its row and another one for its column\n",
    "    reshaped_rho = rho.reshape(np.concatenate((dims_, dims_), axis=None))\n",
    "\n",
    "    # Move the subsystems to be traced towards the end\n",
    "    reshaped_rho = np.moveaxis(reshaped_rho, axis, -1)\n",
    "    reshaped_rho = np.moveaxis(reshaped_rho, len(dims)+axis-1, -1)\n",
    "\n",
    "    # Trace over the very last row and column indices\n",
    "    traced_out_rho = np.trace(reshaped_rho, axis1=-2, axis2=-1)\n",
    "\n",
    "    # traced_out_rho is still in the shape of a tensor\n",
    "    # Reshape back to a matrix\n",
    "    dims_untraced = np.delete(dims_, axis)\n",
    "    rho_dim = np.prod(dims_untraced)\n",
    "    return traced_out_rho.reshape([rho_dim, rho_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e42ca9",
   "metadata": {},
   "source": [
    "***Question 4*** :  We will inject the normalized data $x$ by replacing a node values with $\\frac{I + (2x-1)Z}{2}$. Return the matrix corresponding to the normalized data x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3f0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO return the matrix corresponding to the normalized data x\n",
    "def input_matrix(nb_node, data):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173a69a",
   "metadata": {},
   "source": [
    "***Question 5*** : To replace the node values with new ones, we extract the values of the nodes we want to keep using the partial trace. Then we perform a tensorial product with the matrices of the new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f448b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO input_data take the density matrix and replace the node value by the new input\n",
    "def input_data(nb_node, density_matrix, data):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3addef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_matrix = np.zeros((2**3, 2**3))\n",
    "density_matrix[0,0] = 1\n",
    "input_data(3, density_matrix, [0.1, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64daa6",
   "metadata": {},
   "source": [
    "### 5 - Observable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140aab16",
   "metadata": {},
   "source": [
    "***Question 6*** : We will recover the values of the observables $Z_i$ renormalized between 0 and 1 as observables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO observable return the Zi observable values\n",
    "def observable(nb_node, density_matrix):\n",
    "    res = []\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2b829",
   "metadata": {},
   "source": [
    "### 6 - Reservoir Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20880c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import expm # Do the exponentielle of matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551b48c2",
   "metadata": {},
   "source": [
    "We are now going to evolve our reservoir.\n",
    "\n",
    "To do this, we will follow these steps:\n",
    "- We inject the data in the density_matrix with ```input_data``` function.\n",
    "- We make the reservoir evolve during a time $t$ with the Schrödinger equation.\n",
    "- We stock the observable as results.\n",
    "- We start again with the next piece of data.\n",
    "\n",
    "-------------------------------------------\n",
    "\n",
    "For a density matrix $\\rho$ and a time-independent Hamiltonian $H$, the Schrödinger equation describing the evolution of the system over a time period $t$ is as follows:\n",
    "\n",
    "$\\rho' = \\exp(-iHt) \\rho \\exp(-iHt)$\n",
    "\n",
    "-------------------------------------------\n",
    "\n",
    "In addition to all this, we will introduce the concept of virtual nodes:\n",
    "We measure our system several times between two injections. So instead of evolving our system for a period of time $t$ after injecting the data, we evolve it as many times as there are virtual nodes $nb\\_virtual\\_node$ for a period of time $t/nb\\_virtual\\_node$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb96f7dd",
   "metadata": {},
   "source": [
    "***Question 7*** : Implement the evolution of the reservoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reservoir(nb_node, weigth, data, t=1.0, nb_virtual=10):\n",
    "\n",
    "    # TODO Make a reservoir Hamiltonian\n",
    "    # H = ...\n",
    "\n",
    "    # Initialize the density matrix\n",
    "    density_matrix = np.zeros((2**nb_node, 2**nb_node))\n",
    "    density_matrix[0,0] = 1\n",
    "\n",
    "    # List of results\n",
    "    res = []\n",
    "\n",
    "    for x in data:\n",
    "        # List of virtual nodes\n",
    "        aux=[]\n",
    "        # TODO inject the data x in the density matrix\n",
    "        # density_matrix = ...\n",
    "        for v in range(nb_virtual):\n",
    "            # TODO Evolve the reservoir during a time t/nb_virtual\n",
    "            # density_matrix = ...\n",
    "\n",
    "            # TODO calculate the observables and store them in the virtual node list\n",
    "            # aux += ...\n",
    "\n",
    "        res.append(aux)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5a508",
   "metadata": {},
   "source": [
    "### 7 - A first test: Lorenz attractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://matplotlib.org/stable/gallery/mplot3d/lorenz_attractor.html\n",
    "\n",
    "def lorenz(xyz, *, s=10, r=28, b=2.667):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyz : array-like, shape (3,)\n",
    "       Point of interest in three-dimensional space.\n",
    "    s, r, b : float\n",
    "       Parameters defining the Lorenz attractor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xyz_dot : array, shape (3,)\n",
    "       Values of the Lorenz attractor's partial derivatives at *xyz*.\n",
    "    \"\"\"\n",
    "    x, y, z = xyz\n",
    "    x_dot = s*(y - x)\n",
    "    y_dot = r*x - y - x*z\n",
    "    z_dot = x*y - b*z\n",
    "    return np.array([x_dot, y_dot, z_dot])\n",
    "\n",
    "dt = 0.02\n",
    "num_steps = 11000\n",
    "\n",
    "xyzs = np.empty((num_steps + 1, 3))  # Need one more for the initial values\n",
    "xyzs[0] = (0., 1., 1.05)  # Set initial values\n",
    "# Step through \"time\", calculating the partial derivatives at the current point\n",
    "# and using them to estimate the next point\n",
    "for i in range(num_steps):\n",
    "    xyzs[i + 1] = xyzs[i] + lorenz(xyzs[i]) * dt\n",
    "\n",
    "# Plot\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "ax.plot(*xyzs.T, lw=0.5)\n",
    "ax.set_xlabel(\"X Axis\")\n",
    "ax.set_ylabel(\"Y Axis\")\n",
    "ax.set_zlabel(\"Z Axis\")\n",
    "ax.set_title(\"Lorenz Attractor\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a4624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "xyzs = min_max_scaler.fit_transform(xyzs)\n",
    "x_value = xyzs[:,0].reshape(-1, 1)\n",
    "plt.subplots(figsize=(12, 4))\n",
    "plt.title(\"x value of Lorenz Attractor\")\n",
    "plt.plot(x_value[10000:], label='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random weight for the reservoir\n",
    "def generated_weight(nb_node):\n",
    "    X = np.random.rand(nb_node, nb_node) - 0.5\n",
    "    X[np.diag_indices_from(X)] = np.ones(nb_node)\n",
    "    return X\n",
    "\n",
    "weigth_reservoir = generated_weight(5)\n",
    "\n",
    "embedded_data = Reservoir(5, weigth_reservoir, xyzs, t=4.0)\n",
    "plt.subplots(figsize=(12, 4))\n",
    "plt.title(\"node value\")\n",
    "plt.plot(embedded_data[-1000:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40131efb",
   "metadata": {},
   "source": [
    "### 8 - prediction without reservoir: Lorenz attractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculWeights calculate the pseudo inverse matrix (linear regression) y = x*W\n",
    "def calculWeights(x,y):\n",
    "    Xinv = np.linalg.pinv(x)\n",
    "    Y = np.array(y)\n",
    "    return np.matmul(Xinv, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1e8a9",
   "metadata": {},
   "source": [
    "Here is an example where we use the first 10,000 data points to obtain the W matrix where $xyzs_{k+1} = xyzs{k}*W$. We then use the matrix to predict the last 1,000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1000 # number of steps to predict\n",
    "weights = calculWeights(xyzs[:-1*steps-1,:], xyzs[1:-1*steps,:])\n",
    "x_predict = [xyzs[-1*steps,:]]\n",
    "for i in range(steps):\n",
    "    x_predict.append(np.matmul(x_predict[-1], weights))\n",
    "x_predict = np.array(x_predict)\n",
    "\n",
    "plt.subplots(figsize=(12, 4))\n",
    "plt.title(\"prediction without a reservoir\")\n",
    "plt.plot(x_value[-1*steps:], label='x')\n",
    "plt.plot(x_predict[:,0], label='predicted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86a006",
   "metadata": {},
   "source": [
    "### 9 - prediction with reservoir: Lorenz attractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9491d140",
   "metadata": {},
   "source": [
    "#### 9-1 Prediction 1-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ad091",
   "metadata": {},
   "source": [
    "***Question 8*** : Here we will test the short-term prediction capability. We will pass our entire time series through the reservoir, then use the first 10,000 points to perform a linear regression $xyzs_{k+1} = reservoir(xyzs_{k}) * W $ then use the $W$ weigth to see the prediction for the last 1,000 points. Basically, we predict the next point each time based on the true sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7307c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir_result = Reservoir(5, weigth_reservoir, xyzs, t=4.0)\n",
    "\n",
    "# TODO calcul the Weights (linear regression) as in the previous example (use the first 10,000 data points to calculate the weights)\n",
    "# weights = calculWeights(...)\n",
    "\n",
    "# TODO predict the last 1000 points\n",
    "#x_predict = ...\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(12, 4))\n",
    "plt.title(\"short-term prediction\")\n",
    "plt.plot(x_value[-1000+1:], label='x')\n",
    "# TODO display predicted points\n",
    "#plt.plot(..., label='linear regression values')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986cb4ed",
   "metadata": {},
   "source": [
    "#### 9-2 Prediction N-steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a528768",
   "metadata": {},
   "source": [
    "***Question 9*** : Now we want to use the first 10,000 data points in the sequence to determine $W$, then we will use the formula  $xyzs_{k+1} = reservoir(xyzs_{k}) * W $ to predict $xyzs_{k+1}$ and then inject it into the reservoir, and so on. We are making a long-term prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bacf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(nb_node, weigth, data, steps, t=1.0, nb_virtual=10):\n",
    "\n",
    "    # TODO Make a reservoir Hamiltonian\n",
    "    # H = ...\n",
    "\n",
    "    # Initialize the density matrix\n",
    "    density_matrix = np.zeros((2**nb_node, 2**nb_node))\n",
    "    density_matrix[0,0] = 1\n",
    "\n",
    "    # List of results\n",
    "    res = []\n",
    "\n",
    "    for x in data:\n",
    "        # List of virtual nodes\n",
    "        aux=[]\n",
    "        # TODO inject the data x in the density matrix\n",
    "        # density_matrix = ...\n",
    "\n",
    "        for v in range(nb_virtual):\n",
    "            # TODO Evolve the reservoir during a time t/nb_virtual\n",
    "            # density_matrix = ...\n",
    "\n",
    "\n",
    "            # TODO calculate the observables and store them in the virtual node list\n",
    "            # aux += ...\n",
    "\n",
    "        res.append(aux)\n",
    "    res = np.array(res)\n",
    "\n",
    "    # TODO calcul the Weights (linear regression)\n",
    "    # weights = ...\n",
    "\n",
    "\n",
    "    # TODO predict the initial new data\n",
    "    # new_data = ...\n",
    "    \n",
    "    for i in range(steps):\n",
    "        aux=[]\n",
    "        # TODO inject the last data predicted in the density matrix\n",
    "        # density_matrix = ...\n",
    "\n",
    "        for v in range(nb_virtual):\n",
    "            # TODO Evolve the reservoir during a time t/nb_virtual\n",
    "            # density_matrix = ...\n",
    "\n",
    "            # TODO calculate the observables and store them in the virtual node list\n",
    "            # aux += ...\n",
    "\n",
    "        # TODO Using the new result from the reservoir and the previously calculated weights, predict the new value.\n",
    "        #      And added it to the new_data list\n",
    "        \n",
    "    return np.array(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6fd34",
   "metadata": {},
   "source": [
    "***Question 10*** : Predict the last n steps of the sequence and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 1000\n",
    "new_data = predict(5, weigth_reservoir, xyzs[:-1*n_steps], n_steps, t=4.0)\n",
    "\n",
    "plt.subplots(figsize=(12, 4))\n",
    "plt.title(\"prediction with a reservoir\")\n",
    "plt.plot(x_value[-1000+1:], label='x')\n",
    "# TODO display predicted points\n",
    "#plt.plot(..., label='predicted')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
